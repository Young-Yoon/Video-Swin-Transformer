{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7554a44",
   "metadata": {},
   "source": [
    "# Model inference setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e0d0d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label2idx(file):\n",
    "    w = file.split(\"_\")[-1]\n",
    "    return \"0\" if w[0]=='A' else \"3\" if w[0]=='G' else w[1]\n",
    "\n",
    "from mmaction.models import build_model\n",
    "from mmcv import Config\n",
    "# from mmcv.runner import set_random_seed\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "def val_xdv(filename):\n",
    "    cfg_file = f'configs/recognition/swin/swin_small_patch244_window877_xdviolence_k400_1k.py'\n",
    "    checkpoint_file = f'work_dirs/xdv/best_top1_acc_epoch_15.pth'\n",
    "\n",
    "    cfg = Config.fromfile(cfg_file)\n",
    "    cfg.model.cls_head.num_classes = 7\n",
    "\n",
    "    # model = init_recognizer(cfg_file, checkpoint_file, device=torch.device('cuda:0'))  # or 'cpu'\n",
    "    # Build the recognizer\n",
    "    from mmaction.models import build_model\n",
    "    model = build_model(cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n",
    "    \n",
    "\n",
    "    print('load_checkpoint: ', checkpoint_file)\n",
    "    from mmcv.runner import load_checkpoint\n",
    "    load_checkpoint(model, checkpoint_file)\n",
    "        \n",
    "    from mmaction.apis import single_gpu_test\n",
    "    from mmaction.datasets import build_dataloader, build_dataset\n",
    "    from mmcv.parallel import MMDataParallel\n",
    "\n",
    "    # Build a test dataloader\n",
    "    temp = '/home/ubuntu/swin-data/Video-Swin-Transformer/data/temp'\n",
    "    print(cfg.data.test.data_prefix)\n",
    "    cmd = f\"cp \\\"/home/ubuntu/swin-data/Video-Swin-Transformer/{cfg.data.test['data_prefix']}{filename}\\\" \\\"{temp}\\\"\"\n",
    "    shutil.copy(f\"/home/ubuntu/swin-data/Video-Swin-Transformer/{cfg.data.test['data_prefix']}{filename}\", temp)\n",
    "    cfg.data.test['data_prefix']=temp+'/'\n",
    "    cfg.data.test['ann_file']=temp+'/temp.txt'\n",
    "    with open(cfg.data.test.ann_file, 'w') as f:\n",
    "        f.write(f\"{filename} {label2idx(filename)}\")\n",
    "    \n",
    "    dataset = build_dataset(cfg.data.test, dict(test_mode=True))\n",
    "    print(dataset)\n",
    "    data_loader = build_dataloader(\n",
    "            dataset,\n",
    "            videos_per_gpu=1,\n",
    "            workers_per_gpu=cfg.data.workers_per_gpu,\n",
    "            dist=False,\n",
    "            shuffle=False)\n",
    "    model = MMDataParallel(model, device_ids=[0])\n",
    "    outputs = single_gpu_test(model, data_loader)\n",
    "    os.remove(temp+'/'+filename)\n",
    "    os.remove(cfg.data.test.ann_file)\n",
    "    \n",
    "    return outputs\n",
    "\n",
    "def eval_xdv(outputs, cfg):\n",
    "    eval_config = cfg.evaluation\n",
    "    eval_config.pop('interval')\n",
    "    eval_res = dataset.evaluate(outputs, **eval_config)\n",
    "    for name, val in eval_res.items():\n",
    "        print(f'{name}: {val:.04f}')            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0f8d26",
   "metadata": {},
   "source": [
    "# Demo (gradio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27b0072d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deadpool_2_2018__#0-04-46_0-05-01_label_B2-0-0.mp4\n",
      "load_checkpoint:  work_dirs/xdv/best_top1_acc_epoch_15.pth\n",
      "load checkpoint from local path: work_dirs/xdv/best_top1_acc_epoch_15.pth\n",
      "data/xd-violence/test12/\n",
      "<mmaction.datasets.video_dataset.VideoDataset object at 0x7fd76a151210>\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 1/1, 0.4 task/s, elapsed: 2s, ETA:     0sSin_City_2005__#0-22-04_0-22-18_label_B5-0-0.mp4\n",
      "load_checkpoint:  work_dirs/xdv/best_top1_acc_epoch_15.pth\n",
      "load checkpoint from local path: work_dirs/xdv/best_top1_acc_epoch_15.pth\n",
      "data/xd-violence/test12/\n",
      "<mmaction.datasets.video_dataset.VideoDataset object at 0x7fd768240690>\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 1/1, 0.6 task/s, elapsed: 2s, ETA:     0sv=yDqThVpu1AM__#1_label_B4-0-0.mp4\n",
      "load_checkpoint:  work_dirs/xdv/best_top1_acc_epoch_15.pth\n",
      "load checkpoint from local path: work_dirs/xdv/best_top1_acc_epoch_15.pth\n",
      "data/xd-violence/test12/\n",
      "<mmaction.datasets.video_dataset.VideoDataset object at 0x7fd768226c50>\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 1/1, 0.6 task/s, elapsed: 2s, ETA:     0s"
     ]
    }
   ],
   "source": [
    "# !pip install gradio\n",
    "import gradio as gr\n",
    "import os\n",
    "filepath = '/home/ubuntu/swin-data/Video-Swin-Transformer/data/xd-violence/test12/'\n",
    "x = os.listdir(filepath)\n",
    "\n",
    "def get_inference(filename):\n",
    "    filename=filename.split('/')[-1]\n",
    "    filename=filename[:-44].replace('__', '__#')+filename[-4:]\n",
    "    if filename[0]=='v':  filename = 'v='+filename[1:]\n",
    "    print(filename)\n",
    "    outputs = val_xdv(filename)\n",
    "    import matplotlib.pyplot as plt\n",
    "    fig = plt.figure()\n",
    "    plt.title(filename)\n",
    "    plt.bar(range(7), outputs[0], tick_label=['A:\\nNormal', 'B1:\\nFighting', 'B2:\\nShooting', 'G:\\nExploration', \n",
    "                                               'B4:\\nRiot', 'B5:\\nAbuse', 'B6:\\nCar accident'])\n",
    "    plt.grid()\n",
    "    return fig  # filepath+filename, fig\n",
    "\n",
    "\n",
    "demo = gr.Interface(\n",
    "    fn=get_inference, \n",
    "    inputs=gr.Video(), # gr.Radio(x, label=\"Input Video\"),\n",
    "    outputs=gr.Plot()) #[\"video\", gr.Plot()])\n",
    "    # examples=x, cache_examples=True)\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef4a67d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmlab",
   "language": "python",
   "name": "mmlab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
